<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>BRAIN Forum</title>
        <!-- Favicon-->
        <!-- <link rel="icon" type="image/x-icon" href="assets/favicon.ico" /> -->
        
        <link rel="icon" type="image/png" href="assets/favicon/favicon-96x96.png" sizes="96x96" />
        <link rel="icon" type="image/svg+xml" href="assets/favicon/favicon.svg" />
        <link rel="shortcut icon" href="assets/favicon/favicon.ico" />
        <link rel="apple-touch-icon" sizes="180x180" href="assets/favicon/apple-touch-icon.png" />
        <link rel="manifest" href="assets/favicon/site.webmanifest" />


        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top bg-black" id="mainNav">
            <div class="container">
                <a class="navbar-brand" href="#page-top">
                    <img src="assets/img/brain.svg" alt="..." class="navbar-logo" />
                    <span class="nav-item text-white">BRAIN Forum</span>
                </a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ms-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="#program">Program</a></li>
                        <li class="nav-item"><a class="nav-link" href="#speakers">Speakers</a></li>
                        <li class="nav-item"><a class="nav-link" href="#talks">Talks</a></li>
                        <li class="nav-item"><a class="nav-link" href="#attend">Attend</a></li>
                        <li class="nav-item"><a class="nav-link" href="#organization">Organization</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container">
                <div class="masthead-heading">Europe’s Vision on Responsible AI:<br/>Research, Practice, Policy</div>
                <div class="masthead-subheading">Monday, 28 April 2025</div>
            </div>
        </header>
        <!-- About-->
        <section class="page-section" id="about">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">About</h2>
                </div>
                <div>
                    <p class="text-muted">
                        The <strong>Brussels Responsible AI Network (BRAIN) Forum</strong> is a one-day event that invites researchers, practitioners, and policymakers from Belgium and beyond to discuss the latest advances in AI and its societal implications. 
                        The forum is hosted at the <a href="https://brias.be">Brussels Institute for Advanced Studies (BrIAS)</a> and is part of the BrIAS series of <a href="https://brias.be/en/brias-public-forum-responsible-ai">public forums</a>.
                    </p>
                    <p class="text-muted">
                        BRAIN brings together the three Belgian AI research programmes: the <a href="https://www.fari.brussels">AI for the Common Good Institute (FARI)</a> in Brussels; the <a href="https://trail.ac/en/">Trusted AI Labs (TRAIL)</a> of the Walloon and Brussels regions; and the <a href="https://www.flandersairesearch.be/en/">Flanders AI Research programme (FAIR)</a>.
                    </p>
                    <p class="text-muted">
                        The BRAIN Forum is co-organised by the <a href="https://brias.be">Brussels Institute for Advanced Studies (BrIAS)</a>, <a href="https://www.ulb.be">Université Libre de Bruxelles (ULB)</a>, <a href="https://www.vub.be">Vrije Universiteit Brussel (VUB)</a>, <a href="https://www.fari.brussels">AI for the Common Good Institute (FARI)</a>, and <a href="https://www.unamur.be/en">Université de Namur (UNamur)</a>, with funding from the <a href="https://brias.be">Brussels Institute of Advanced Studies (BrIAS)</a>, the <a href="https://www.frs-fnrs.be/en/">Fund for Scientific Research (F.R.S.–FNRS)</a>, and the European Union.
                    </p>
                    <p class="text-muted">
                        The BRAIN Forum is structured around four sessions:
                        <ul class="text-muted">
                            <li>The <strong><a href="#research">research session</a></strong> provides an expert-driven overview of emerging trends in responsible AI.
                            <li>The <strong><a href="#practice">practice session</a></strong> explores practical perspectives on implementing responsible AI.</li>
                            <li>The <strong><a href="#policy">policy session</a></strong> addresses Europe’s global position on responsible AI.</li>
                            <li>The <strong><a href="#networking">networking session</a></strong> aims to foster collaboration among Belgian AI labs and provides a platform for participants to present their expertise and project ideas.</li>
                        </ul>
                    </p>
                </div>
            </div>
        </section>
        <!-- Program-->
        <section class="page-section bg-light" id="program">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Program</h2>
                </div>
                    <!-- <p class="text-muted">
                        A detailed program is coming up.
                    </p> -->
                    <div class="row">
                        <div class="col-lg-2 col-md-2 col-sm-2 mb-5"></div>
                        <div class="col-lg-8 col-md-8 col-sm-8 mb-5">
                        <br/>
                            <table class="text-muted" style="margin: 0 auto;">
                                <thead>
                                    <tr>
                                    <th>Start</th>
                                    <th>End</th>
                                    <th>Session</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                    <td>08:00</td>
                                    <td></td>
                                    <td>Doors Open</td>
                                    </tr>
                                    <tr>
                                    <td>08:30</td>
                                    <td>09:00</td>
                                    <td>Welcome and Introduction</td>
                                    </tr>
                                    <tr>
                                    <td>09:00</td>
                                    <td>10:40</td>
                                    <td><strong><a href="#research">Session 1 - Research</a></strong></td>
                                    </tr>
                                    <tr>
                                    <td>10:40</td>
                                    <td>11:00</td>
                                    <td>Coffee Break</td>
                                    </tr>
                                    <tr>
                                    <td>11:00</td>
                                    <td>13:00</td>
                                    <td><strong><a href="#practice">Session 2 - Practice</a></strong></td>
                                    </tr>
                                    <tr>
                                    <td>13:00</td>
                                    <td>14:00</td>
                                    <td>Lunch</td>
                                    </tr>
                                    <tr>
                                    <td>14:00</td>
                                    <td>15:30</td>
                                    <td><strong><a href="#policy">Session 3 - Policy</a></strong></td>
                                    </tr>
                                    <tr>
                                    <td>15:30</td>
                                    <td>16:00</td>
                                    <td>Coffee Break</td>
                                    </tr>
                                    <tr>
                                    <td>16:00</td>
                                    <td>17:30</td>
                                    <td><strong><a href="#networking">Session 4 - Networking</a></strong></td>
                                    </tr>
                                    <tr>
                                    <td>17:30</td>
                                    <td></td>
                                    <td>Reception</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="col-lg-2 col-md-2 col-sm-2 mb-5"></div>
                    </div>
                    <div class="mt-5">
                        <ul class="timeline">
                            <li class="timeline-inverted" id="research">
                                <div class="timeline-image"><img class="img-fluid" src="assets/img/program/1.research.jpg" alt="research" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                        <h3>Session 1 - Research</h3>
                                        <h5 class="subheading">Advancing Responsible AI: Developments at the Research Level</h5>
                                    </div>
                                    <div class="timeline-body"><p class="text-muted">This session provides an expert-driven overview of emerging research trends in responsible AI.
                                    </p><br/></div>
                                    <table class="table text-muted">
                                        <tbody>
                                            <tr>
                                                <td>09:00</td>
                                                <td>09:25</td>
                                                <td>
                                                    <a href="#speaker-stefanowski"><strong>Jerzy Stefanowski</strong></a> (Poznan University of Technology, Poland)<br/>
                                                    <a href="#talk-stefanowski">"The Role of Counterfactual Explanations: New Methods and Open Challenges"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>09:25</td>
                                                <td>09:50</td>
                                                <td>
                                                    <a href="#speaker-stefanidis"><strong>Kostas Stefanidis</strong></a> (Tampere University, Finland)<br/>
                                                    <a href="#talk-stefanidis">"Responsible Recommender Systems"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>09:50</td>
                                                <td>10:15</td>
                                                <td>
                                                    <a href="#speaker-ntoutsi"><strong>Eirini Ntoutsi</strong></a> (Bundeswehr University Munich, Germany)<br/>
                                                    <a href="#talk-ntoutsi">"From Single Focus to Intersectional Perspective: Tackling Multi-dimensional Discrimination in AI"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>10:15</td>
                                                <td>10:40</td>
                                                <td>
                                                    <a href="#speaker-zuidema"><strong>Willem Zuidema</strong></a> (University of Amsterdam, the Netherlands)<br/>
                                                    <a href="#talk-zuidema">"The Explanation Conundrum: Why XAI Methods Don’t Work Well Enough Yet for AI That Really Matters"</a>
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="practice">
                                <div class="timeline-image"><img class="img-fluid" src="assets/img/program/2.practice.jpg" alt="practice" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                        <h3>Session 2 - Practice</h3>
                                        <h5 class="subheading">Implementing Responsible AI: Approaches from Research Programs, Academia, and Industry</h5>
                                    </div>
                                    <div class="timeline-body"><p class="text-muted">This session includes practical perspectives on responsible AI from the three Belgian AI research programs (FARI, FAIR, and TRAIL), academia, and industry.
                                    </p><br/></div>
                                    <table class="table text-muted">
                                        <tbody>
                                            <tr>
                                                <td>11:00</td>
                                                <td>11:15</td>
                                                <td>
                                                    <a href="#speaker-lenaerts"><strong>Tom Lenaerts</strong></a> (ULB, Belgium)<br/>
                                                    <a href="#talk-lenaerts">"If FARI Is the Answer, What Was the Question?"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>11:15</td>
                                                <td>11:30</td>
                                                <td>
                                                    <a href="#speaker-geurts"><strong>Pierre Geurts</strong></a> (ULiège, Belgium)<br/>
                                                    <a href="#talk-geurts">"The Perspective of TRAIL (Trusted AI Labs) on Responsible AI"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>11:30</td>
                                                <td>11:45</td>
                                                <td>
                                                    <a href="#speaker-demey"><strong>Sabine Demey</strong></a> (Flanders AI Research program and imec, Belgium)<br/>
                                                    <a href="#talk-demey">"The Perspective of FAIR (Flanders AI Research program) on Responsible AI"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>11:45</td>
                                                <td>12:05</td>
                                                <td>
                                                    <a href="#speaker-ginis"><strong>Vincent Ginis</strong></a> (VUB, Belgium)<br/>
                                                    <a href="#talk-ginis">"Work, Teach, and Learn with Generative AI"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>12:05</td>
                                                <td>12:30</td>
                                                <td>
                                                    <a href="#speaker-rawat"><strong>Ambrish Rawat</strong></a> (IBM Research, Ireland)<br/>
                                                    <a href="#talk-rawat">"Securing Generative AI"</a>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>12:30</td>
                                                <td>13:00</td>
                                                <td>
                                                    <a href="#speaker-germanakos"><strong>Panagiotis Germanakos</strong></a> (SAP SE, Germany)<br/>
                                                    <a href="#talk-germanakos">"Trust in AI: The Human-Computer Interaction Perspective"</a>
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="policy">
                                <div class="timeline-image"><img class="img-fluid" src="assets/img/program/3.policy.jpg" alt="policy" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                        <h3>Session 3 - Policy</h3>
                                        <h5 class="subheading">Shaping Responsible AI: Europe’s Global Position on Responsible AI</h5>
                                    </div>
                                    <div class="timeline-body"><p class="text-muted">This session includes presentations and a panel on the EU’s policy and strategic approach to responsible AI, featuring insights from the European AI Office.
                                    </p><br/></div>
                                    <table class="table text-muted">
                                        <tbody>
                                            <tr>
                                                <td>14:00</td>
                                                <td>15:00</td>
                                                <td>
                                                    <strong>Opening Statements</strong>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-machala"><strong>Milena Machała</strong></a> (European AI Office)<br/>
                                                    <a href="#talk-panel-machala">"The European AI Strategy"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-moreau"><strong>Yves Moreau</strong></a> (KU Leuven, Belgium)<br/>
                                                    <a href="#talk-panel-moreau">"Dual-Use Research in the Horizon Program: Feeding an AI Arms Race?"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-demay"><strong>Sabine Demey</strong></a> (Flanders AI Research program and imec, Belgium)<br/>
                                                    <a href="#talk-panel-demay">"Responsible AI Is Crucial for Value Creation With AI at Scale"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-lewkowicz"><strong>Grégory Lewkowicz</strong></a> (ULB, Belgium)<br/>
                                                    <a href="#talk-panel-lewkowicz">"Will the European Digital Omnibus Run Over Responsible AI?"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-frenay"><strong>Benoît Frénay</strong></a> (UNamur, Belgium)<br/>
                                                    <a href="#talk-panel-frenay">"Implementing the AI Act: Mission Impossible?"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    <a href="#speaker-libin"><strong>Pieter Libin</strong></a> (VUB, Belgium)<br/>
                                                    <a href="#talk-panel-libin">"Why We Need a CERN, Not a Manhattan Project"</a><br/>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>15:00</td>
                                                <td>15:30</td>
                                                <td>
                                                    <strong>Panel Discussion</strong>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td></td>
                                                <td></td>
                                                <td>
                                                    Moderated by <a href="#speaker-heyman"><strong>Rob Heyman</strong></a> (VUB, Belgium)<br/>
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="networking">
                                <div class="timeline-image"><img class="img-fluid" src="assets/img/program/4.networking.jpg" alt="networking" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                        <h3>Session 4 - Networking</h3>
                                        <h5 class="subheading">Connecting for Responsible AI: Showcasing Project Ideas and Research Expertise</h5>
                                    </div>
                                    <div class="timeline-body"><p class="text-muted">This session fosters networking among members of Belgium’s three AI research programmes and explores opportunities for collaboration.
                                    </p><br/></div>
                                    <table class="table text-muted">
                                        <tbody>
                                            <tr>
                                                <td>16:00</td>
                                                <td>17:30</td>
                                                <td>
                                                    <strong>Flash Presentations</strong>
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        <!-- Speakers-->
        <section class="page-section" id="speakers">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Speakers</h2>
                </div>
                <div>
                    <div class="mt-5">
                        <ul class="timeline">
                            <li class="timeline-inverted" id="speaker-stefanowski">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/stefanowski.jpg" alt="Jerzy Stefanowski" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Jerzy Stefanowski</strong> (Poznan University of Technology, Poland)</h5>
                                    </div>
                                    <div>
                                    <p>Jerzy Stefanowski works as a full professor at Poznan University of Technology, Institute of Computing Science. He received his Ph.D and Habilitation degrees from the same University. In 2021 he was elected as a corresponding member of Polish Academy of Sciences, where he also plays a role of a Chair of Scientific Council of Institute of Computer Science (IPI PAN) in Warsaw. His research interests include data mining, machine learning and XAI. Major results are concerned with: ensemble classifiers, learning from class-imbalanced data, online learning from evolving data streams, explainable AI, induction of various types of rules, data preprocessing, generalizations of rough set theory, descriptive clustering of texts and medical applications of data mining. He is the author and co-author of over 170 research papers and 2 books, which are highly cited. Moreover, he was a visiting professor or researcher in several universities, mainly in France, Italy, Belgium, Spain and Germany.</p>

                                    <p>In addition to his research activities, he served in a number of organizational capacities: including positions in bodies of Polish Academy of Sciences, current vice-president of Polish Artificial Intelligence Society (vice-president since 2014); co-founder and co-leader of Polish Special Interest Group on Machine Learning. Moreover, he is the Editor in Chief of Foundations of Computing and Decision Science journal since 2012 and Action Editor of other journals.</p>
                                    
                                    <p>More information can be found at <a href="http://www.cs.put.poznan.pl/jstefanowski/">http://www.cs.put.poznan.pl/jstefanowski/</a>.</p>
                                    <!-- <p style="text-align: right"><a id="back-link" href="javascript:void(0);" onclick="history.back();"><img src="assets/img/arrow-return-left.svg"></a></p> -->
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-stefanidis">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/stefanidis.jpg" alt="Kostas Stefanidis" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Kostas Stefanidis</strong> (Tampere University, Finland)</h5>
                                    </div>
                                    <div>
                                    <p>Kostas Stefanidis is a Professor on Data Science at the Faculty of Information Technology and Communication Sciences of the Tampere University in Finland, where he also leads the Data Science Research Centre and the Group on Recommender Systems. He has more than 10 years of experience in different roles at ICS-FORTH in Greece, NTNU in Norway and CUHK in Hong Kong. He got his PhD in personalized data management from the Univ. of Ioannina in Greece. His research interests are in the broader area of big data. His work focuses on personalization and recommender systems, entity resolution, data exploration and data analytics, with a special focus recently on socio-technical aspects in data management like fairness and transparency, and published in more than 100 papers in top-tier conferences and journals. He has been involved in several international and national research projects, and he is also actively serving the scientific community. Currently, he is the General co-Chair of ADBIS 2025, TPDL 2025, and EDBT/ICDT 2026.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-ntoutsi">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/ntoutsi.jpg" alt="Eirini Ntoutsi" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Eirini Ntoutsi</strong> (Bundeswehr University Munich, Germany)</h5>
                                    </div>
                                    <div>
                                    <div>
                                    <p>
                                    Prof. Eirini Ntoutsi is Professor for Open Source Intelligence at the Department of Computer Sciences of the University of the Bundeswehr Munich. Her research interests lie in the fields of Artificial Intelligence (AI) and Machine Learning (ML). She has been focusing on designing intelligent algorithms that learn from data continuously following the cumulative nature of human learning, while ensuring that what has been learned helps driving positive societal impact. Her current research areas include continuous learning over non-stationary data and data streams, responsible AI and in particular fairness-aware machine learning and explainable AI, and generative AI, that is using machines to generate new plausible data and artifacts.
                                    </p>
                                    <p>
                                    Prof. Ntoutsi is an active member of the research community serving regularly as a program committee member for several conferences and workshops. She was for instance co-chair or co-organizer multiple times for essential conferences and workshops such as CIKM, ICDM, ECMLPKDD or AAAI on topics like bias and fairness in AI, evaluation and experimental design in data mining and machine learning, or business applications of social network analysis. In 2018 she was co-organizer of the Dagstuhl perspectives workshop 18262 “10 years of Web Science: Closing the Loop" and is currently guest editor for the special issue on bias and fairness in AI in the Data Mining and Knowledge Discovery journal. Prof. Ntoutsi is a member of ACM, IEEE and German Informatics Society (GI). Her research is supported by several national (DFG, Volkswagen Foundation, BMWi, BMBF) and EU funds (ITN, H2020).
                                    </p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-zuidema">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/zuidema.jpg" alt="Willem Zuidema" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Willem Zuidema</strong> (University of Amsterdam, the Netherlands)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Willem Zuidema is an Associate Professor in Natural Language Processing, Explainable AI, and Cognitive Modelling at the Institute for Logic, Language and Computation. His research focuses on these areas, and he leads the Cognition, Language and Computation Lab, supervising several PhD and MSc students. He teaches in the interdisciplinary Master’s programmes in Artificial Intelligence and Brain & Cognitive Sciences, and coordinates the Cognitive Science track within the MBCS. He also occasionally gives public talks on artificial intelligence and the evolution of language.
                                    </p>
                                    <p>More information can be found at <a href="https://staff.fnwi.uva.nl/w.zuidema/">https://staff.fnwi.uva.nl/w.zuidema/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-lenaerts">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/lenaerts.jpg" alt="Tom Lenaerts" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Tom Lenaerts</strong> (ULB, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Tom Lenaerts is Professor in the Computer Science department at the Université Libre de Bruxelles (ULB), where he is co-heading the Machine Learning Group (MLG). He holds a partial affiliation as research professor with the Artificial Intelligence Lab of the Vrije Universiteit Brussel and is affiliated researcher at the Center for Human-Compatible AI of UC Berkeley. He was board member, vice-chair and finally chair of the Benelux Association for Artificial Intelligence between 2016 and 2024.  He currently is the Academic Director of FARI, the Brussels AI for Common Good institute, AI expert in the Global Partnership on Artificial Intelligence and national contact point for the CAIRNE hub in Brussels. He has been publishing in a variety of interdisciplinary domains on AI and Machine Learning, involving topics related to optimization, multi-agent systems, collective intelligence, evolutionary game theory, computational biology and bioinformatics.
                                    </p>
                                    <p>More information can be found at <a href="https://mlg.ulb.ac.be/wordpress/members/tom-lenaerts/">https://mlg.ulb.ac.be/wordpress/members/tom-lenaerts/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-geurts">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/geurts.jpg" alt="Pierre Geurts" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Pierre Geurts</strong> (ULiège, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Pierre Geurts is a full professor in the EECS department at the University of Liège (Montefiore Institute). He received his degree in electrical engineering (computer science) in 1998 and his PhD in applied sciences in 2002 from the University of Liège. From 2005 to 2007, he held a CNRS postdoctoral position at the University of Evry (France) and from 2006 to 2011, he was a research associate of the FNRS (Belgium). His research interests include the design, empirical and theoretical analysis of machine learning algorithms, with a focus on scalability, explainability, and usability of these algorithms. He develops real-world applications of these techniques in various fields, including computational and systems biology, computer vision and digital humanities. Pierre is the acting president of TRAIL for the 2024-2025 academic year.
                                    </p>
                                    <p>More information can be found at <a href="https://people.montefiore.uliege.be/geurts/">https://people.montefiore.uliege.be/geurts/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-demey">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/demey.jpg" alt="Sabine Demey" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Sabine Demey</strong> (Flanders AI Research program and imec, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Sabine Demey is the director of the Flanders AI Research Program (FAIR). She brings together researchers from 11 research partners in Flanders (universities and research centres). Together they tackle challenging AI Research Challenges and apply the new AI methods in healthcare, in industry 5.0, for the energy transition, in society. She believes it is important for technological developments such as AI to have a meaningful impact on people, industry and society. Sabine is a computer scientist and holds a PhD in robotics. Prior to leading the AI Research Program in Flanders since 2020, she has 20+ years industrial experience in research, product and business development, software for the manufacturing industry and for healthcare.
                                    </p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-ginis">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/ginis.png" alt="Vincent Ginis" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Vincent Ginis</strong> (VUB, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Vincent Ginis received his B.Sc. degree in engineering, summa cum laude, in 2007, and the M.Sc. degree in Photonics Engineering, summa cum laude, in 2009 from the Vrije Universiteit Brussel (Belgium). In May 2014, he received the degree of doctor in applied sciences, summa cum laude and felicitations of the exam committee. Currently, Vincent is appointed as an assistant professor at the Vrije Universiteit Brussel. He also works as a visiting professor in the group of Prof. Federico Capasso at Harvard University.
                                    </p>
                                    <p>
                                    To date, Vincent has published his research in around 20 international publications with a high impact factor, including 1 article in the Proceedings of the National Academy of Sciences, several letters in Physical Review Letters–among which 2 cover articles–and many publications that were highlighted as Editor’s Suggestion. He has presented his work in more than 40 international conference proceedings and he was invited or plenary speaker at 9 international conferences.
                                    </p>
                                    <p>
                                    Vincent has received many national and international awards, including Agathon De Potter Award in Physics (2018), the Solvay Award for PhD dissertations (2016), the Vocatio fellowship (2015), the FWO/BCG Best Paper Award (2014), the international SPIE Scholarship in Optical Science and Engineering (2013), the IEEE Photonics Graduate Student fellowship (2012), the KVIV engineering award (2010), and the FWO/Barco Award (2010). Vincent also serves as an editor of the journal Applied Metamaterials and as a reviewer for several important journals in his field, including Nature Photonics, Physical Review Letters, Nature Communications, and New Journal of Physics. He is also member of the scientific committee of several international conferences, including SPIE Photonics Europe and META. Vincent regularly appears in the general media to discuss research breakthroughs. In 2017, he was elected as one of the 10 new members of the Young Academy of Belgium and as one of the top 50 tech pioneers in Belgium.
                                    </p>
                                    <p>More information can be found at <a href="https://ai.vub.ac.be/team/vincent-ginis/">https://ai.vub.ac.be/team/vincent-ginis/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-rawat">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/rawat.jpg" alt="Ambrish Rawat" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Ambrish Rawat</strong> (IBM Research, Ireland)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Ambrish Rawat is a senior research professional specializing in AI Safety and Security, with a focus on red-teaming, risk assessment, and building safeguards for trustworthy AI deployment. At IBM, he leads efforts in red-teaming and the development of security safeguards such as Granite Guardian. With expertise in adversarial machine learning and generative AI, he has driven product innovation, contributed to EU-funded initiatives, and advanced research aimed at supporting the responsible use of AI technologies.
                                    </p>
                                    <p>More information can be found at <a href="https://research.ibm.com/people/ambrish-rawat">https://research.ibm.com/people/ambrish-rawat</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-germanakos">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/germanakos.png" alt="Panagiotis Germanakos" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Panagiotis Germanakos</strong> (SAP SE, Germany)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Panagiotis Germanakos is a Principal User Experience Research Scientist and Instructor at SAP SE, leading and supporting user research initiatives of product teams for delivering usable, high quality, human-centred solutions. As an SAP University Alliances Ambassador, he acts as a liason between industry and academia, consulting and sharing knowledge to inspire innovation. For many years, he has been exploring the human-machine interaction, striving to understand their evolving symbiosis. His research focuses on the coexistence of human-, artificial-, and quantum- intelligence in developing optimal, adaptive, and personalized solutions tailored to individual users. In 2021, he co-founded PulseX Non-Profit Research Institute, dedicated to promoting responsible scientific research, knowledge, and innovations that enhance human experiences and improve lives. He holds a PhD in Human-Centered Computing from the National & Kapodistrian University of Athens (2008) and has authored over 140 publications in top-tier conferences and journals, including nine books. His work has received multiple awards, along with seven patents. Additionally, he is a co-founder of international scientific events such as the ACM HAAPIE and HUMANIZE workshop series. He actively serves on editorial boards, program committees, and advisory panels for leading conferences and journals, including ACM UMAP, IUI, INTERACT, and CHI. He is also a member of international research networks and professional organizations such as ACM SIGCHI, AIS, and the Expert Network of HCI-KDD.
                                    </p>
                                    <p>More information can be found at <a href="http://pgermanakos.com/">http://pgermanakos.com/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-machala">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/machala.jpg" alt="Milena Machała" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Milena Machała</strong> (European AI Office)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Milena Machała is an Antitrust Lawyer, and a Legal and Policy Officer in the European AI Office.
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-moreau">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/moreau.jpg" alt="Yves Moreau" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Yves Moreau</strong> (KU Leuven, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Yves Moreau is a professor at the University of Leuven, Belgium. His team develops machine learning methods for clinical genetics and drug discovery: (1) privacy-preserving analysis of clinical genetic data, (2) data fusion algorithms for the identification of candidate disease genes and variants in rare genetic disorders, and (3) data fusion for drug discovery and drug design. Methodologically, he focuses on the development of novel artificial intelligence methods (Bayesian matrix factorization and deep learning) for the fusion of heterogeneous, sparsely observed data, and on privacy-preserving implementations of such methods. He aims at demonstrated clinical or industrial applicability of those methods and proven effectiveness in human genetics research and drug discovery. He is a tech innovator interested in identifying relevant business models for emerging technologies and developing projects up to the precompetitive stage and the startup of university spin-offs. He was a co-founder of Data4S, a data mining company specialized in fraud detection and anti-moneylaundering, which is now part of BAE Systems. He was also a co-founder of Cartagenia, specialized in ICT solutions for clinical genetic diagnosis, now part of Agilent Technologies. He is also engaged in a reflection on how information technology and artificial intelligence are transforming our world and on how to make sure this transformation is beneficial for all.
                                    </p>
                                    <p>More information can be found at <a href="https://ai.kuleuven.be/members/00012794">https://ai.kuleuven.be/members/00012794</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-lewkowicz">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/lewkowicz.jpg" alt="Grégory Lewkowicz" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Grégory Lewkowicz</strong> (ULB, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Former representative of the National Fund for Scientific Research (F.R.S.-FNRS), Grégory Lewkowicz is a professor at the Université libre de Bruxelles, a member of the Perelman Centre, and the director of the SMART Law Hub within the Faculty of Law and Criminology. He is also the academic director at the Institute of Artificial Intelligence for the Common Good (FARI) in Brussels. He teaches the course “Smart Law: Algorithms, Metrics & Artificial Intelligence” at Sciences Po Law School in Paris. Additionally, he lectures at Paris II Panthéon-Assas University and the University of Liège. He is a Koyré Senior Research Fellow in Economic Law and Artificial Intelligence as part of the 3IA Chair at Université Côte d’Azur. He is also a recurring professor in the executive education programs on digital transformation and law at HEC-Paris.
                                    </p>
                                    <p>
                                    His research pragmatically examines the interactions between law and digital technologies (SMART Law), global and transnational law, as well as the contemporary transformations of law and legal professions. He leads several research programs on algorithmic law and the application of artificial intelligence techniques to the development, analysis, implementation, and enforcement of legal or related norms. He is also involved in multiple research and development projects with public and private partners. Grégory Lewkowicz frequently advises public authorities and companies on digital strategy and regulation.
                                    </p>
                                    <p>
                                    Grégory Lewkowicz oversees the “Penser le droit” collection at Bruylant Publishing. He serves on the board of directors of the European Academy of Legal Theory and the Brussels Academic Higher Education Pole. He is a member of the advisory board of AI4Belgium and the European Committee on AI (AI Board). He established the Brussels Bar Observatory and chaired the European Incubator of the Brussels Bar from 2017 to 2022.
                                    </p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-frenay">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/frenay.jpg" alt="Benoît Frénay" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Benoît Frénay</strong> (UNamur, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Benoît Frénay is an associate professor at the Faculty of Computer Science of the Université de Namur. He completed a degree in computing science engineering (specialising in artificial intelligence) in 2007 at the Université catholique de Louvain. Then, he obtained a PhD in the UCL Machine Learning Group in 2013. The topic of his thesis was Uncertainty and Label Noise in Machine Learning. In parallel, he also completed a master’s in pedagogy in 2010 with a focus on problem-based learning. Additionally, he had the opportunity to undertake research stays at Aalto University, Radboud University Nijmegen, and the CITEC centre of excellence at Bielefeld University. In 2014, he received the Scientific Prize IBM Belgium for Informatics for his PhD thesis.
                                    </p>
                                    <p>
                                    His main research interests in machine learning include support vector machines, label noise, efficient learning, graphical models, classification, clustering, density estimation, interpretability, visualisation, and feature selection. He enjoys collaboration and is open to new topics, including projects in partnership with enterprises (industry, IT, etc.).
                                    </p>
                                    <p>More information can be found at <a href="https://bfrenay.wordpress.com">https://bfrenay.wordpress.com</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-libin">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/libin.webp" alt="Pieter Libin" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Pieter Libin</strong> (VUB, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Prof. Pieter Libin graduated in 2014 with a Master’s degree in Informatics from the Vrije Universiteit Brussel (VUB), where he also obtained his PhD in Computer Science in 2020. Following his doctoral studies, he was awarded a personal postdoctoral fellowship by the Research Foundation – Flanders (FWO) and continued his research at the Data Science Institute of Hasselt University. Since October 2021, Pieter has been serving as an assistant professor at the Artificial Intelligence Lab of VUB.
                                    </p>
                                    <p>
                                    His research focuses on leveraging machine learning to support decision-making, integrating advanced learning techniques with realistic simulation models. His work spans both theoretical and applied AI, with particular emphasis on reinforcement learning and Bayesian modeling. He has extensive experience in modeling and analyzing complex real-world systems, including virus diversity, epidemic outbreaks, and renewable energy systems.
                                    </p>
                                    <p>
                                    In 2024, Pieter was elected as a member of the Jonge Academie, a dynamic community of young top researchers and artists committed to engaging with policy, society, research, and the arts.
                                    </p>
                                    <p>More information can be found at <a href="https://ai.vub.ac.be/team/pieter-libin/">https://ai.vub.ac.be/team/pieter-libin/</a>.</p>
                                    </div>
                                </div>
                            </li>
                            <li class="timeline-inverted" id="speaker-heyman">
                                <div class="timeline-image person"><img class="rounded-circle img-fluid" src="assets/img/speakers/heyman.png" alt="Rob Heyman" /></div>
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5><strong>Rob Heyman</strong> (VUB, Belgium)</h5>
                                    </div>
                                    <div>
                                    <p>
                                    Rob Heyman is a coordinator of the Knowledge Centre Data and Society which  is part of the Flemish strategic plan on AI. He is a senior researcher at imec-SMIT where he researches participative methods in innovation projects between different stakeholders (legal, civil society, end-users) so that societal, legal and ethical values are integrated during development. He also has given lectures and courses at the ULB and VUB on online marketing, research methods, privacy and challenges of the ongoing digitalisation.
                                    </p>
                                    <p>More information can be found at <a href="https://smit.research.vub.be/en/prof-dr-rob-heyman">https://smit.research.vub.be/en/prof-dr-rob-heyman</a>.</p>
                                    </div>
                                </div>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        <!-- Talks-->
        <section class="page-section" id="talks">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Talks</h2>
                </div>
                <div>
                    <div class="mt-5">
                        <div class="mb-5">
                        <p>
                        <h3>Session 1 - Research</h3><br/>
                        </p>
                            <div id="talk-stefanowski" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>The Role of Counterfactual Explanations: New Methods and Open Challenges</h5>
                                    <p><strong>Jerzy Stefanowski</strong> (Poznan University of Technology, Poland)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Explaining the predictions of modern black-box machine learning systems is essential for the development of trustworthy artificial intelligence. In this talk we will discuss counterfactual explanations (counterfactuals), which provides information about how the description of an example should be changed in order to obtain a more desired prediction of the machine learning model. In order to generate a good counterfactual, several desirable properties are formulated, such as the validity of the decision change, its proximity to the input instance, the sparsity of the recommended changes, its actionability, its plausibility and others The talk will cover recent author’s works on handling plausible counterfactuals, and ongoing research on robust explanations to model changes. The final part of this talk will address selected open research questions and challenges.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-stefanidis" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Responsible Recommender Systems</h5>
                                    <p><strong>Kostas Stefanidis</strong> (Tampere University, Finland)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Due to the significant impact of recommendations on users’ experiences and the often sensitive nature of recommendation tasks, it is crucial to carefully design the processes by which recommendations are generated. This has led to a growing emphasis on developing recommender systems that adhere to key principles of responsibility, such as fairness—ensuring the absence of bias—and transparency—enhancing user understanding of system decisions. In this talk, we will present a toolkit of definitions, models, and methods for promoting fairness in recommender systems, with a special focus on group recommendations. Additionally, since users may struggle to comprehend why a particular suggestion is made, many systems incorporate explanations to improve transparency. We will discuss different types of explanations in recommender systems, including why-not and counterfactual explanations, both for individual users and groups.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-ntoutsi" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>From Single Focus to Intersectional Perspective: Tackling Multi-dimensional Discrimination in AI</h5>
                                    <p><strong>Eirini Ntoutsi</strong> (Bundeswehr University Munich, Germany)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Despite growing attention to fairness in AI systems, many approaches still focus on single identity attributes (mono-discrimination). However, human identities are inherently multi-dimensional, and discrimination can manifest across various social identities—such as race, gender, disability, class, and sexual orientation (multi-discrimination).
                                    In this presentation, we explore the challenges posed by multidimensional discrimination, highlighting how the intersection of social identities complicates both the definition and measurement of fairness. We also discuss the challenges of learning in such settings, particularly in the face of data scarcity that affects both group and class levels. Finally, we present approaches to mitigating multidimensional discrimination, with a particular focus on a multi-objective optimization framework as an effective strategy for balancing multiple, often conflicting, learning goals.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-zuidema" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>The Explanation Conundrum: Why XAI Methods Don’t Work Well Enough Yet for AI That Really Matters</h5>
                                    <p><strong>Willem Zuidema</strong> (University of Amsterdam, the Netherlands)</p>
                                    </div>
                                    <div>
                                    <p>
                                    The field of explainable AI (XAI) has developed many techniques to explain the inner workings of popular 'blackbox' AI models, and thus adress 'the blackbox problem' that plagues deep learning and generative AI. Unfortunately, however, these explanation methods themselves are often untrustworthy: it is difficult to demonstrate that their explanations are really faithful to underlying causes in the blackbox model, and alternative explainers often produce radically different explanations in practice. In this talk I explain this 'explanation conundrum' and the practical challenges it presents for policy makers, and I sketch a possible way out, based on ongoing technical research in 'mechanistic interpretability' and 'disentanglement'.
                                    </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="mb-5">
                            <p>
                            <h3>Session 2 - Practice</h3><br/>
                            </p>
                            <div id="talk-lenaerts" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>If FARI Is the Answer, What Was the Question?</h5>
                                    <p><strong>Tom Lenaerts</strong> (ULB, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-geurts" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>The Perspective of TRAIL (Trusted AI Labs) on Responsible AI</h5>
                                    <p><strong>Pierre Geurts</strong> (ULiège, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    This talk will present TRAIL's perspective on Responsible AI. TRAIL, for Trusted AI Labs, is a research and business community that brings together the expertise of all French-speaking universities and four research centers active in the field of AI. TRAIL is strongly supported by federal and regional strategic players such as DigitalWallonia4.AI and AI4Belgium, as well as an international pool of AI experts. Our mission is to develop a trusted approach to artificial intelligence, ensuring that it becomes a transformative force for our societies and contributes to the sustainable well-being of citizens. TRAIL’s research is organized around four key research themes (human-AI interaction, trustworthy AI, model-driven AI, and embedded and green AI), which collectively contribute to the development of Responsible AI. Recently, we introduced a fifth cross-cutting research theme that specifically addresses the societal, legal, and ethical dimensions of AI, with the dual goals of informing researchers and businesses about these dimensions and ensuring that ethical and legal considerations are integrated into the technical innovations emerging from the ecosystem.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-demey" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>The Perspective of FAIR (Flanders AI Research Program) on Responsible AI</h5>
                                    <p><strong>Sabine Demey</strong> (Flanders AI Research program and imec, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Responsible AI is integrated in the Flanders AI Research program at various levels.
                                    All partners are responsible for compliance with existing regulations. We also adhere to ethical principles and reflect on ethical impacts of research. We run responsible AI self-assessments on the use cases in the program and emphasize the responsible use of AI in research for all participants in the program. The choice of use cases and research themes also reflects the attention for Responsible AI, with focus on use cases with meaningful impact on people, society, economy, planet  and with central research themes such as trustworthy AI (explainable AI, fairness, causal learning and causality inference) and resource-efficient AI (energy-efficient AI, data-efficient AI).
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-ginis" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Work, Teach, and Learn with Generative AI</h5>
                                    <p><strong>Vincent Ginis</strong> (VUB, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-rawat" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Securing Generative AI</h5>
                                    <p><strong>Ambrish Rawat</strong> (IBM Research, Ireland)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Generative AI is redefining the software landscape and the threat surface that comes with it. This talk will cover two complementary pillars of Securing Gen AI: red-teaming and safeguards. It will begin by mapping the novel attacks that target AI systems—like prompt-injection and jailbreaks to emergent agent-level exploits—and trace how automated red-team pipelines, driven by AI themselves, can systematically uncover these risks. It will then pivot to defensive engineering: constructing and benchmarking guardrails. Throughout, it will focus on how products operationalise these ideas, highlight latest research, and outline the open challenges that must be solved to help with responsible deployment of generative systems at enterprise scale.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-germanakos" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Trust in AI: The Human-Computer Interaction Perspective</h5>
                                    <p><strong>Panagiotis Germanakos</strong> (SAP SE, Germany)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Artificial Intelligence is revolutionizing Human-Computer Interaction (HCI) and User Experience (UX), redefining design principles and transforming human-AI relationships. Yet, trust remains a critical challenge, users hesitate to trust what they don't understand. While transparency in algorithmic processes and decision-making is essential for building confidence, a fundamental question persists: How can we make complex AI systems truly accessible and relatable, particularly for non-experts? This talk embraces an innovative approach through visual storytelling, bridging the gap between AI's technical complexities and human understanding. We present an academic graphic novel that reveals the hidden world of algorithms, networks, and logical decision-making. The narrative follows Agent Black, an AI entity that mimics human behavior, as it navigates decentralized digital landscapes to complete a seemingly simple task: finding the perfect birthday venue. By anthropomorphizing AI's challenges, including ethical dilemmas, computational constraints, and decision-making processes, we transform abstract concepts into tangible human experiences. Combining humor, narrative tension, and expert insights, the graphic novel turns computational logic into an engaging and intuitive journey. Ultimately, this talk explores how HCI and UX can reshape AI's future as a trustworthy, comprehensible partner in our daily lives.
                                    </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="mb-5">
                            <p>
                            <h3>Session 3 - Policy</h3><br/>
                            </p>

                            <div id="talk-panel-machala" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>The European AI Strategy</h5>
                                    <p><strong>Milena Machała</strong> (European AI Office)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-panel-moreau" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Dual-use research in the Horizon program: Feeding an AI arms race?</h5>
                                    <p><strong>Yves Moreau</strong> (KU Leuven, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    Because of the ongoing war in Ukraine and the political shift in the US, European countries are taking steps to mobilize society towards military sovereignty. A key element in this regard is the move of the EU Horizon program away from exclusive civilian purposes and towards “embracing dual use”? Is such a move compatible with the mission of universities to disseminate knowledge globally and their commitments to peace? The rapid development of AI can also lead to new or vastly more effective weapons enabling crimes against humanity, terrorism, and authoritarian regimes, including at home. Researchers and universities must carefully consider their moral responsibility before engaging in such research. One should also ask whether in such a context “responsible AI” would still be meaningful or amount to “ethics washing”.
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-panel-demay" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Responsible AI Is Crucial for Value Creation With AI at Scale</h5>
                                    <p><strong>Sabine Demay</strong> (Flanders AI Research program and imec, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-panel-lewkowicz" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Will the European Digital Omnibus Run Over Responsible AI?</h5>
                                    <p><strong>Grégory Lewkowicz</strong> (ULB, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <div id="talk-panel-frenay" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Implementing the AI Act: Mission Impossible?</h5>
                                    <p><strong>Benoît Frénay</strong> (UNamur, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    The AI Act has gone far beyond the classical questions of interpretability and explainability raised earlier by the GDPR. It entails requirements on the ethics, robustness, security, reproducibility and trustworthiness of AI systems. Verifying the conformity of AI systems in specific domains will require an enormous number of trained experts, which raises the question: how can Europe ensure that it is able to actually enforce the AI Act and related frameworks? We will shortly discuss this and stress the importance of accelerating the education of a new generation of technical experts that are well versed in legal matters (incl. AI Act and related digital regulations).
                                    </p>
                                    </div>
                                </div>
                            </div>
                            <!-- <div id="talk-panel-lenaerts" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>TBA</h5>
                                    <p><strong>Tom Lenaerts</strong> (ULB, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    </p>
                                    </div>
                                </div>
                            </div> -->
                            <div id="talk-panel-libin" class="mb-5">
                                <div class="timeline-panel">
                                    <div class="timeline-heading">
                                    <h5>Why We Need a CERN, Not a Manhattan Project</h5>
                                    <p><strong>Pieter Libin</strong> (VUB, Belgium)</p>
                                    </div>
                                    <div>
                                    <p>
                                    As artificial general intelligence (AGI) moves from speculation to serious ambition, its development is increasingly driven by a handful of powerful tech companies, often with minimal public oversight or international coordination. While AGI holds promise for solving global challenges—like disease, climate change, and economic inequality—it also presents profound risks, from societal disruption to existential threats. In this session, Pieter Libin explores the political dynamics shaping AGI, the concentration of control in corporate hands, and the dangers of treating its development as a zero-sum race between nations. He argues for an alternative vision: an internationally governed, collaborative approach—more like CERN than a Manhattan Project—that puts safety, transparency, and shared benefit at the center of AI progress.
                                    </p>
                                    </div>
                                </div>
                            </div>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        <!-- Attend-->
        <section class="page-section bg-light" id="attend">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Attend</h2>
                </div>
                <div>
                    <p class="text-muted">
                        The event will be held at the BrIAS seminar room, <a href="https://maps.app.goo.gl/Zw24zNs8wYqP5NXu5">Blvd General Jacques 210, USquare Building AB-0, 1050 Ixelles, Belgium</a>. Participation is free of charge, but registration is required. <br/><br/>
                    </p>
                    <!-- <p class="text-muted"> -->
                    <div class="text-center">
                        <h3 class="text-uppercase"><a href="https://forms.office.com/Pages/ResponsePage.aspx?id=qHxbaagtRUWi2kLQN4TlhfyNSeuI0m9AmKo3tf0yiP5UNVg2SjBSM0lFR1hMN0ZMTVpDVEM4MUpPVS4u">Register here</a></h3>
                    </div>
                    <!-- </p> -->

            </div>
        </section>
        <!-- Organization-->
        <section class="page-section" id="organization">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Organization</h2>
                </div>
                <div class="row">
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/dimitris.jpg" alt="Dimitris Sacharidis" />
                            <h4>Dimitris Sacharidis</h4>
                            <p class="text-muted">Université Libre de Bruxelles</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://dsachar.net" aria-label="Dimitris Sacharidis Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/dsachar/" aria-label="Dimitris Sacharidis LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/leander.jpg" alt="Leander Schietgat" />
                            <h4>Leander Schietgat</h4>
                            <p class="text-muted">Vrije Universiteit Brussel</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://ai.vub.ac.be/team/leander-schietgat/" aria-label="Leander Schietgat Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/leander-schietgat-5107b61" aria-label="Leander Schietgat LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/carl.jpg" alt="Carl Mörch" />
                            <h4>Carl Mörch</h4>
                            <p class="text-muted">FARI</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.fari.brussels/researcher/carl-morch" aria-label="Carl Mörch Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/carl-maria-mörch-99429976" aria-label="Carl Mörch LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/benoît.jpg" alt="Benoît Frénay" />
                            <h4>Benoît Frénay</h4>
                            <p class="text-muted">Université de Namur</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://bfrenay.wordpress.com" aria-label="Benoît Frénay Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/benoît-frénay-253a465/" aria-label="Benoît Frénay LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/emanuele.jpg" alt="Emanuele Garone" />
                            <h4>Emanuele Garone</h4>
                            <p class="text-muted">Université Libre de Bruxelles</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://brias.be/en/prof-dr-emanuele-garone" aria-label="Emanuele Garone Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://brias.be/linkedin.com/in/egarone" aria-label="Emanuele Garone LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/ann.jpg" alt="Ann Nowé" />
                            <h4>Ann Nowé</h4>
                            <p class="text-muted">Vrije Universiteit Brussel</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://ai.vub.ac.be/team/ann-nowe/" aria-label="Ann Nowé Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/ann-nowe-5ba2b8" aria-label="Ann Nowé LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/anja.webp" alt="Anja Garone" />
                            <h4>Anja Garone</h4>
                            <p class="text-muted">Brussels Institute for Advanced Studies</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://brias.be/nl/node/204" aria-label="Anja Garone Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/anja-garone-10790b95" aria-label="Anja Garone LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                    <div class="col-lg-3">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="assets/img/team/mehrdad.jpg" alt="Mehrdad Asadi" />
                            <h4>Mehrdad Asadi</h4>
                            <p class="text-muted">Vrije Universiteit Brussel</p>
                            <a class="btn btn-dark btn-social mx-2" href="https://ai.vub.ac.be/team/mehrdad-asadi/" aria-label="Mehrdad Asadi Homepage"><i class="fa-solid fa-house"></i></a>
                            <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/mehrdad-asadi-216148123" aria-label="Mehrdad Asadi LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Logos-->
        <div class="py-5">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://brias.be"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/brias.jpg" alt="..." aria-label="BrIAS Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://www.frs-fnrs.be/en/"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/fnrs.png" alt="..." aria-label="FNRS Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/EU.png" alt="..." aria-label="EU Logo" />
                    </div>
                </div>
                <div class="row align-items-center">
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://www.ulb.be"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/ulb.png" alt="..." aria-label="ULB Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://www.vub.be/en"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/vub.svg" alt="..." aria-label="VUB Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="http://www.unamur.be/en"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/unamur.svg" alt="..." aria-label="UNamur Logo" /></a>
                    </div>
                </div>
                <div class="row align-items-center">
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://www.fari.brussels"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/fari.svg" alt="..." aria-label="FARI Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://www.flandersairesearch.be/en"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/fair.png" alt="..." aria-label="FAIR Logo" /></a>
                    </div>
                    <div class="col-md-4 col-sm-4 my-3">
                        <a href="https://trail.ac/en/"><img class="img-fluid img-brand d-block mx-auto" src="assets/img/logos/trail.png" alt="..." aria-label="TRAIL Logo" /></a>
                    </div>
                </div>
            </div>
        </div>
        <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-start">Copyright &copy; BRAIN 2025</div>
                </div>
            </div>
        </footer>
       <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
